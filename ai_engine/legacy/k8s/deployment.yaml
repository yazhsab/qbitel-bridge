# CRONOS AI Legacy System Whisperer - Kubernetes Deployment
# Production-ready Kubernetes configuration

apiVersion: v1
kind: Namespace
metadata:
  name: cronos-ai-legacy
  labels:
    name: cronos-ai-legacy
    component: ai-engine
    version: v1.0.0

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: legacy-whisperer-config
  namespace: cronos-ai-legacy
data:
  config.yaml: |
    legacy_system_whisperer:
      enabled: true
      service_name: "legacy-system-whisperer"
      version: "1.0.0"
      max_registered_systems: 5000
      max_concurrent_analyses: 50
      memory_limit_mb: 8192
      
      anomaly_detection:
        anomaly_threshold: 0.98
        critical_anomaly_threshold: 0.99
        llm_analysis_enabled: true
        detection_interval_seconds: 180
        enable_real_time_alerts: true
        cache_ttl_seconds: 7200
        
      predictive_analytics:
        failure_prediction_enabled: true
        min_historical_data_days: 90
        prediction_confidence_threshold: 0.85
        llm_prediction_enhancement: true
        
      knowledge_capture:
        llm_processing_enabled: true
        session_timeout_minutes: 120
        peer_review_required: true
        audit_trail_enabled: true
        knowledge_retention_days: 1825
        
      decision_support:
        recommendation_enabled: true
        max_recommendations: 10
        multi_llm_consensus: true
        llm_recommendation_enhancement: true
        
      llm_integration:
        primary_provider: "openai"
        fallback_providers: ["anthropic"]
        max_tokens: 4000
        temperature: 0.05
        timeout_seconds: 30
        response_validation: true
        
      monitoring:
        metrics_collection_enabled: true
        prometheus_enabled: true
        health_check_enabled: true
        metrics_collection_interval: 30
        
      security:
        encrypt_sensitive_data: true
        audit_logging: true
        compliance_reporting: true
        gdpr_compliance: true

---
apiVersion: v1
kind: Secret
metadata:
  name: legacy-whisperer-secrets
  namespace: cronos-ai-legacy
type: Opaque
data:
  # Base64 encoded secrets (replace with actual values)
  db-password: Y3Jvbm9zMTIz  # cronos123
  redis-password: Y3Jvbm9zMTIz  # cronos123
  jwt-secret: bGVnYWN5LXNlY3JldC1rZXktcHJvZC0yMDI0  # legacy-secret-key-prod-2024
  openai-api-key: c2stWVlZWVlZWVlZWVlZWVlZWVlZWVlZWVlZWVlZWVlZWA==  # placeholder
  anthropic-api-key: c2stYW50aHJvcGljLWtleS1oZXJl  # placeholder

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: legacy-whisperer
  namespace: cronos-ai-legacy
  labels:
    app: legacy-whisperer
    component: ai-engine
    version: v1.0.0
spec:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1
  selector:
    matchLabels:
      app: legacy-whisperer
  template:
    metadata:
      labels:
        app: legacy-whisperer
        component: ai-engine
        version: v1.0.0
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/path: "/metrics"
        prometheus.io/port: "8080"
    spec:
      serviceAccountName: legacy-whisperer
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
      containers:
      - name: legacy-whisperer
        image: cronos-ai/legacy-whisperer:v1.0.0
        imagePullPolicy: Always
        ports:
        - containerPort: 8000
          name: http
          protocol: TCP
        - containerPort: 8080
          name: metrics
          protocol: TCP
        env:
        # Database configuration
        - name: CRONOS_AI_DB_HOST
          value: "postgres-service"
        - name: CRONOS_AI_DB_PORT
          value: "5432"
        - name: CRONOS_AI_DB_NAME
          value: "cronos_ai"
        - name: CRONOS_AI_DB_USER
          value: "cronos"
        - name: CRONOS_AI_DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: legacy-whisperer-secrets
              key: db-password
        
        # Redis configuration
        - name: CRONOS_AI_REDIS_HOST
          value: "redis-service"
        - name: CRONOS_AI_REDIS_PORT
          value: "6379"
        - name: CRONOS_AI_REDIS_PASSWORD
          valueFrom:
            secretKeyRef:
              name: legacy-whisperer-secrets
              key: redis-password
        
        # Service configuration
        - name: CRONOS_AI_ENVIRONMENT
          value: "production"
        - name: CRONOS_AI_LOG_LEVEL
          value: "INFO"
        - name: CRONOS_AI_DEBUG
          value: "false"
        
        # Security configuration
        - name: CRONOS_AI_JWT_SECRET
          valueFrom:
            secretKeyRef:
              name: legacy-whisperer-secrets
              key: jwt-secret
        - name: CRONOS_AI_ENCRYPT_SENSITIVE_DATA
          value: "true"
        
        # LLM API Keys
        - name: OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: legacy-whisperer-secrets
              key: openai-api-key
        - name: ANTHROPIC_API_KEY
          valueFrom:
            secretKeyRef:
              name: legacy-whisperer-secrets
              key: anthropic-api-key
        
        # Monitoring
        - name: JAEGER_AGENT_HOST
          value: "jaeger-agent"
        - name: JAEGER_AGENT_PORT
          value: "6831"
        
        # Legacy System Whisperer specific
        - name: CRONOS_AI_LEGACY_ENABLED
          value: "true"
        - name: CRONOS_AI_LEGACY_MAX_SYSTEMS
          value: "5000"
        - name: CRONOS_AI_LEGACY_MEMORY_LIMIT_MB
          value: "8192"
        
        resources:
          requests:
            memory: "2Gi"
            cpu: "1000m"
          limits:
            memory: "8Gi"
            cpu: "4000m"
        
        volumeMounts:
        - name: config-volume
          mountPath: /app/config
          readOnly: true
        - name: logs-volume
          mountPath: /app/logs
        - name: data-volume
          mountPath: /app/data
        
        livenessProbe:
          httpGet:
            path: /api/v1/legacy-system-whisperer/health
            port: 8000
          initialDelaySeconds: 60
          periodSeconds: 30
          timeoutSeconds: 10
          failureThreshold: 3
        
        readinessProbe:
          httpGet:
            path: /api/v1/legacy-system-whisperer/health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        
        startupProbe:
          httpGet:
            path: /api/v1/legacy-system-whisperer/health
            port: 8000
          initialDelaySeconds: 10
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 30
      
      volumes:
      - name: config-volume
        configMap:
          name: legacy-whisperer-config
      - name: logs-volume
        emptyDir:
          sizeLimit: 10Gi
      - name: data-volume
        persistentVolumeClaim:
          claimName: legacy-whisperer-data
      
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - legacy-whisperer
              topologyKey: kubernetes.io/hostname

---
apiVersion: v1
kind: Service
metadata:
  name: legacy-whisperer-service
  namespace: cronos-ai-legacy
  labels:
    app: legacy-whisperer
    component: ai-engine
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/path: "/metrics"
    prometheus.io/port: "8080"
spec:
  type: ClusterIP
  ports:
  - port: 8000
    targetPort: 8000
    protocol: TCP
    name: http
  - port: 8080
    targetPort: 8080
    protocol: TCP
    name: metrics
  selector:
    app: legacy-whisperer

---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: legacy-whisperer
  namespace: cronos-ai-legacy
  labels:
    app: legacy-whisperer
    component: ai-engine

---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  namespace: cronos-ai-legacy
  name: legacy-whisperer-role
rules:
- apiGroups: [""]
  resources: ["configmaps", "secrets"]
  verbs: ["get", "list"]
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "list"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: legacy-whisperer-rolebinding
  namespace: cronos-ai-legacy
subjects:
- kind: ServiceAccount
  name: legacy-whisperer
  namespace: cronos-ai-legacy
roleRef:
  kind: Role
  name: legacy-whisperer-role
  apiGroup: rbac.authorization.k8s.io

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: legacy-whisperer-data
  namespace: cronos-ai-legacy
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 100Gi
  storageClassName: fast-ssd

---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: legacy-whisperer-hpa
  namespace: cronos-ai-legacy
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: legacy-whisperer
  minReplicas: 3
  maxReplicas: 20
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  - type: Pods
    pods:
      metric:
        name: legacy_whisperer_requests_per_second
      target:
        type: AverageValue
        averageValue: "100"
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 10
        periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60

---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: legacy-whisperer-pdb
  namespace: cronos-ai-legacy
spec:
  minAvailable: 2
  selector:
    matchLabels:
      app: legacy-whisperer

---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: legacy-whisperer-ingress
  namespace: cronos-ai-legacy
  annotations:
    kubernetes.io/ingress.class: nginx
    cert-manager.io/cluster-issuer: letsencrypt-prod
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/proxy-body-size: "50m"
    nginx.ingress.kubernetes.io/rate-limit: "1000"
    nginx.ingress.kubernetes.io/rate-limit-window: "1m"
spec:
  tls:
  - hosts:
    - legacy-api.cronos-ai.com
    secretName: legacy-whisperer-tls
  rules:
  - host: legacy-api.cronos-ai.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: legacy-whisperer-service
            port:
              number: 8000

---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: legacy-whisperer-network-policy
  namespace: cronos-ai-legacy
spec:
  podSelector:
    matchLabels:
      app: legacy-whisperer
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: ingress-nginx
    ports:
    - protocol: TCP
      port: 8000
  - from:
    - namespaceSelector:
        matchLabels:
          name: monitoring
    ports:
    - protocol: TCP
      port: 8080
  egress:
  - to:
    - namespaceSelector:
        matchLabels:
          name: cronos-ai-data
    ports:
    - protocol: TCP
      port: 5432
    - protocol: TCP
      port: 6379
  - to: []
    ports:
    - protocol: TCP
      port: 443  # HTTPS for LLM APIs
    - protocol: TCP
      port: 53   # DNS
    - protocol: UDP
      port: 53   # DNS

---
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: legacy-whisperer-monitor
  namespace: cronos-ai-legacy
  labels:
    app: legacy-whisperer
    component: ai-engine
spec:
  selector:
    matchLabels:
      app: legacy-whisperer
  endpoints:
  - port: metrics
    interval: 30s
    path: /metrics
    honorLabels: true

---
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: legacy-whisperer-alerts
  namespace: cronos-ai-legacy
  labels:
    app: legacy-whisperer
    component: ai-engine
spec:
  groups:
  - name: legacy-whisperer
    rules:
    - alert: LegacyWhispererDown
      expr: up{job="legacy-whisperer-service"} == 0
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: "Legacy System Whisperer is down"
        description: "Legacy System Whisperer has been down for more than 5 minutes"
    
    - alert: LegacyWhispererHighErrorRate
      expr: rate(legacy_whisperer_errors_total[5m]) > 0.1
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "High error rate in Legacy System Whisperer"
        description: "Error rate is above 10% for the last 5 minutes"
    
    - alert: LegacyWhispererHighLatency
      expr: histogram_quantile(0.95, rate(legacy_whisperer_request_duration_seconds_bucket[5m])) > 2
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "High latency in Legacy System Whisperer"
        description: "95th percentile latency is above 2 seconds"
    
    - alert: LegacyWhispererHighMemoryUsage
      expr: container_memory_usage_bytes{pod=~"legacy-whisperer-.*"} / container_spec_memory_limit_bytes > 0.9
      for: 10m
      labels:
        severity: warning
      annotations:
        summary: "High memory usage in Legacy System Whisperer"
        description: "Memory usage is above 90% for the last 10 minutes"